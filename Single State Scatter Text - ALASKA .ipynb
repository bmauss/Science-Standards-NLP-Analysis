{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom functions \n",
    "from projectfunctions import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import spacy \n",
    "import scattertext as st \n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the NGSS and Arizona state standards & apply preprocessing methods including tokenizing, removing stop words to the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ngss corpus\n",
    "ngss = open_and_flatten('TXTfiles/ngss')   \n",
    "\n",
    "#create a nested list\n",
    "s = ['ngss'] \n",
    "s.append(ngss) \n",
    "\n",
    "#create a ngss dataframe\n",
    "ngss_corpi = pd.DataFrame(s, columns=[\"corpus\"]) \n",
    "ngss_corpi['state'] = \"ngss\" \n",
    "ngss_corpi = ngss_corpi.drop([0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alaska corpus \n",
    "arizona = open_and_flatten('TXTfiles/alaska')  \n",
    "\n",
    "#create a nested list\n",
    "a = ['alaska'] \n",
    "a.append(arizona) \n",
    "\n",
    "#create a alaska dataframe\n",
    "state_corpi = pd.DataFrame(a, columns=[\"corpus\"]) \n",
    "state_corpi['state'] = \"alaska\" \n",
    "state_corpi = state_corpi.drop([0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'dept', 'education', 'early', 'development', '...</td>\n",
       "      <td>alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'topic', 'arrangements', 'next', 'generation',...</td>\n",
       "      <td>ngss</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              corpus   state\n",
       "1  'dept', 'education', 'early', 'development', '...  alaska\n",
       "1  'topic', 'arrangements', 'next', 'generation',...    ngss"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#join states & ngss\n",
    "standards_corpi = pd.concat([state_corpi, ngss_corpi], axis=0)  \n",
    "  \n",
    "\n",
    "#clearn corpus column\n",
    "standards_corpi['corpus'] = standards_corpi['corpus'].astype(str)  \n",
    "standards_corpi['corpus'] = standards_corpi['corpus'].apply(lambda x: \n",
    "                                                            x.strip(\"[\")\n",
    "                                                            .strip(\"]\"))\n",
    "\n",
    "standards_corpi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose the Arizona state standards because they are heavily aligned with the NGSS standards so should produce a high number of similar points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn text into a Scattertext Corpus \n",
    "nlp = spacy.load('en')\n",
    "corpus = st.CorpusFromPandas(standards_corpi, \n",
    "                            category_col='state', \n",
    "                            text_col='corpus', \n",
    "                            nlp=nlp).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Unique Words:\n",
      "- crosscutting\n",
      "- dcis\n",
      "- abstractly\n",
      "- ngss\n",
      "- geosphere\n",
      "- clarification\n",
      "- progresses\n",
      "- hydrosphere\n",
      "- embryological\n",
      "- delimiting\n"
     ]
    }
   ],
   "source": [
    "print(\"Corpus Unique Words:\")\n",
    "word = list(corpus.get_scaled_f_scores_vs_background().index[:10]) \n",
    "for w in word: \n",
    "    print(\"-\", w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alaska:\n",
      "- concepts constructing\n",
      "- ideas crosscutting\n",
      "- understanding develop\n",
      "- practices disciplinary\n",
      "- education engineering\n",
      "- elements framework\n",
      "- developed using\n",
      "- following elements\n",
      "- using following\n",
      "- expectations developed\n",
      "- engineering practices\n",
      "- developed\n",
      "- following\n",
      "- crosscutting concepts\n",
      "- elements\n",
      "- crosscutting\n",
      "- demonstrate understanding\n",
      "- understanding use\n",
      "- understanding construct\n",
      "- ice\n"
     ]
    }
   ],
   "source": [
    "#words most associated with aligned states \n",
    "print(\"Alaska:\")\n",
    "term_freq_df = corpus.get_term_freq_df()\n",
    "term_freq_df['Alaska'] = corpus.get_scaled_f_scores('alaska')\n",
    "al = list(term_freq_df.sort_values(by='Alaska', ascending=False) \n",
    "          .index[:20])\n",
    "for a in al: \n",
    "    print(\"-\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NGSS:\n",
      "- progresses\n",
      "- experiences progresses\n",
      "- achieve reserved\n",
      "- reserved\n",
      "- national academy\n",
      "- verbatim framework\n",
      "- academy sciences\n",
      "- academy\n",
      "- permission\n",
      "- reprinted\n",
      "- section entitled\n",
      "- entitled disciplinary\n",
      "- ideas reproduced\n",
      "- verbatim\n",
      "- education practices\n",
      "- entitled\n",
      "- ' achieve\n",
      "- practices cross\n",
      "- ideas integrated\n",
      "- integrated reprinted\n"
     ]
    }
   ],
   "source": [
    "#words most associated with aligned states \n",
    "print(\"NGSS:\")\n",
    "term_freq_df = corpus.get_term_freq_df()\n",
    "term_freq_df['NGSS'] = corpus.get_scaled_f_scores('ngss')\n",
    "al = list(term_freq_df.sort_values(by='NGSS', ascending=False) \n",
    "          .index[:20])\n",
    "for a in al: \n",
    "    print(\"-\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012185"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = st.produce_scattertext_explorer(corpus, \n",
    "                                       category='ngss',\n",
    "                                       category_name='NGSS',\n",
    "                                       not_category_name='Alaska',\n",
    "                                       width_in_pixels=1000)\n",
    "open(\"AZ_NGSS_Visualization.html\", 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
